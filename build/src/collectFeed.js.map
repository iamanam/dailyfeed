{"version":3,"sources":["../../server/src/collectFeed.js"],"names":["rootPath","process","env","join","__dirname","Promise","require","scrapDescription","itemUrl","scrapeIdentity","cheerioReq","err","$","totalNews","console","log","$links","i","length","push","eq","text","resolve","altDes","htmlToText","fromString","item","description","hideLinkHrefIfSameAsText","ignoreHref","ignoreImage","formatItem","descriptin","local","newsSetting","scrapping","link","img","tag","undefined","title","pubDate","image","result","Error","CollectFeed","sourceTitle","sourceUrl","lastFirstFeedTitle","scrapTag","jsonFile","feedCollection","fetch","writeFile","fileName","fileToWrite","writeJson","e","processWrite","dataToWrite","self","fileFolder","ensureDir","formatXml","reject","Response","pipe","obj","chunk","enc","callback","isUpdateAvailable","then","v","on","data","timeNow","Date","now","feedsLength","feeds","initCollect","getXml","body","processXml"],"mappings":";;;;;;;;;;;;;;;;;;;;;;;;AAAA;;;;AACA;;;;AACA;;;;AACA;;;;AACA;;AACA;;;;AACA;;;;;;;;AACA,IAAMA,WAAWC,QAAQC,GAAR,CAAYF,QAAZ,IAAwB,eAAKG,IAAL,CAAUC,SAAV,EAAqB,IAArB,EAA2B,IAA3B,CAAzC;AACA,IAAIC,UAAUC,QAAQ,UAAR,CAAd;;AAEA;;;;;;;AAOA,IAAMC,mBAAmB,SAAnBA,gBAAmB,CAACC,OAAD,EAAUC,cAAV,EAA6B;AACpD,MAAMC,aAAaJ,QAAQ,aAAR,CAAnB;AACA,SAAO,IAAID,OAAJ,CAAY,mBAAW;AAC5BK,eAAWF,OAAX,EAAoB,UAACG,GAAD,EAAMC,CAAN,EAAY;AAC9B,UAAIC,YAAY,EAAhB;AACA,UAAIF,GAAJ,EAASG,QAAQC,GAAR,CAAYJ,GAAZ;AACT,UAAIK,SAASJ,EAAEH,cAAF,CAAb;AACA,WAAK,IAAIQ,IAAI,CAAb,EAAgBA,IAAID,OAAOE,MAA3B,EAAmC,EAAED,CAArC,EAAwC;AACtCJ,kBAAUM,IAAV,CAAeH,OAAOI,EAAP,CAAUH,CAAV,EAAaI,IAAb,EAAf;AACD;AACDC,cAAQT,SAAR;AACD,KARD;AASD,GAVM,CAAP;AAWD,CAbD;;AAeA,IAAMU,SAAS,SAATA,MAAS,OAAQ;AACrB,MAAMC,aAAalB,QAAQ,cAAR,CAAnB;AACA,SAAOkB,WAAWC,UAAX,CACLC,KAAKC,WAAL,IACED,KAAK,iBAAL,EAAwB,CAAxB,CADF,IAEE,0BAHG,EAIL;AACEE,8BAA0B,IAD5B;AAEEC,gBAAY,IAFd;AAGEC,iBAAa;AAHf,GAJK,CAAP;AAUD,CAZD;AAaA;;;;;;AAMA,IAAMC;AAAA,0DAAa,iBAAeL,IAAf,EAAqBjB,cAArB;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,kBACbiB,QAAQ,QAAOA,IAAP,yCAAOA,IAAP,OAAgB,QADX;AAAA;AAAA;AAAA;;AAEXM,sBAFW;;AAAA,iBAGX,iBAAOC,KAAP,CAAaC,WAAb,CAAyBC,SAHd;AAAA;AAAA;AAAA;;AAAA;AAAA,mBAIM5B,iBAAiBmB,KAAKU,IAAtB,EAA4B3B,cAA5B,CAJN;;AAAA;AAIbuB,sBAJa;AAAA;AAAA;;AAAA;AAKRA,yBAAaT,OAAOG,IAAP,CAAb;;AALQ;AAKmB;;AAElC;AACA;AACIW,eATW,GASLX,KAAK,WAAL,CATK;;AAUf,gBAAIW,GAAJ,EAAS;AACHC,iBADG,GACGD,IAAI,GAAJ,MAAaE,SAAb,GACNF,IAAI,KAAJ,IAAaA,IAAI,KAAJ,EAAW,GAAX,CAAb,GAA+B,MADzB,GAENA,IAAI,GAAJ,CAHG;AAIR;AAdc;AAAA,mBAeI;AACjBG,qBAAOd,KAAKc,KADK;AAEjBb,2BAAaK,UAFI;AAGjBS,uBAASf,KAAKe,OAHG;AAIjBC,qBAAOJ,GAJU;AAKjBF,oBAAMV,KAAKU;AALM,aAfJ;;AAAA;AAeXO,kBAfW;AAAA,6CAsBRA,MAtBQ;;AAAA;AAAA,kBAwBXC,MAAM,8BAAN,CAxBW;;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,GAAb;;AAAA;AAAA;AAAA;AAAA,GAAN;;AA2BA,IAAMC,cAAc,SAAdA,WAAc,CAASC,WAAT,EAAsBC,SAAtB,EAAiCC,kBAAjC,EAAqD;AAAA;;AACvE,OAAKD,SAAL,GAAiBA,SAAjB;AACA,OAAKD,WAAL,GAAmBA,WAAnB;AACA,OAAKG,QAAL,GAAgB,iBAAOH,WAAP,EAAoBI,QAApC;AACA,OAAKC,cAAL,GAAsB,EAAtB;AACA,OAAKC,KAAL;AACA,OAAKC,SAAL,GAAiB,UAACC,QAAD,EAAWC,WAAX,EAA2B;AAC1C,QAAI;AACF,UAAI,OAAOA,WAAP,KAAuB,WAA3B,EAAwC;AACtC,0BAAGC,SAAH,CACE,eAAKrD,IAAL,CAAUH,QAAV,EAAoB,OAApB,EAA6B,MAAK8C,WAAlC,EAA+CQ,WAAW,OAA1D,CADF,EAEEC,WAFF;AAIAzC,gBAAQC,GAAR,CAAY,qBAAZ,EAAmC,MAAK+B,WAAxC;AACD;AACF,KARD,CAQE,OAAOW,CAAP,EAAU;AACV3C,cAAQC,GAAR,CAAY0C,CAAZ;AACD;AACF,GAZD;AAaA,OAAKC,YAAL,GAAoB,UAACJ,QAAD,EAAWK,WAAX,EAA2B;AAC7C,QAAIC,YAAJ;AACA,QAAIC,aAAa,eAAK1D,IAAL,CAAUH,QAAV,EAAoB,OAApB,EAA6B,MAAK8C,WAAlC,CAAjB;AACA,sBAAGgB,SAAH,CAAaD,UAAb,EAAyB,aAAK;AAC5BD,WAAKP,SAAL,CAAeC,QAAf,EAAyBK,WAAzB;AACD,KAFD;AAGD,GAND;AAOA,MAAIC,OAAO,IAAX;AACA,OAAKG,SAAL,GAAiB,oBAAY;AAC3B,WAAO,IAAI1D,OAAJ,CAAY,UAACiB,OAAD,EAAU0C,MAAV,EAAqB;AACtC,UAAIb,iBAAiB,EAArB;AACA,aAAOc,SAASC,IAAT,CAAc,0BAAd,EACJA,IADI,CAEH,kBAASC,GAAT,CAAa,UAASC,KAAT,EAAgBC,GAAhB,EAAqBC,QAArB,EAA+B;AAAA;;AAC1C;AACA;AACA;AACA,YAAIF,MAAM5B,KAAN,KAAgBQ,kBAApB,EAAwC;AACtC,iBAAO1B,QAAQ,EAAEiD,mBAAmB,KAArB,EAAR,CAAP;AACD;AACD;AACA,YAAIlE,OAAJ,CAAY,UAACiB,OAAD,EAAU0C,MAAV,EAAqB;AAC/B1C,kBAAQS,WAAWqC,KAAX,EAAkBR,KAAKX,QAAvB,CAAR;AACD,SAFD,EAEGuB,IAFH,CAEQ,aAAK;AACX,iBAAKrD,IAAL,CAAUsD,CAAV;AACAH;AACD,SALD;AAMD,OAdD,CAFG,EAkBJI,EAlBI,CAkBD,OAlBC,EAkBQ,aAAK;AAChB,cAAM9B,MAAMa,CAAN,CAAN;AACD,OApBI,EAqBJiB,EArBI,CAqBD,MArBC,EAqBO,gBAAQ;AAClBvB,uBAAewB,KAAKnC,KAApB,IAA6BmC,IAA7B;AACD,OAvBI,EAwBJD,EAxBI,CAwBD,KAxBC,EAwBM,YAAM;AACf,YAAIE,UAAUC,KAAKC,GAAL,EAAd,CADe,CACW;;AAE1B,cAAKpB,YAAL,CAAkBkB,OAAlB,EAA2BzB,cAA3B;AACA7B,gBAAQ;AACNyD,uBAAa,oBAAY5B,cAAZ,EAA4BjC,MADnC;AAENoC,oBAAUsB,UAAU,OAFd;AAGNI,iBAAO7B,cAHD;AAINoB,6BAAmB;AAJb,SAAR;AAMD,OAlCI,CAAP;AAmCD,KArCM,CAAP;AAsCD,GAvCD;;AAyCA,OAAKU,WAAL,gDAAmB;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,mBAEIrB,KAAKR,KAAL,CAAWL,SAAX,CAFJ;;AAAA;AAEXmC,kBAFW;AAAA;AAAA,mBAGQtB,KAAKG,SAAL,CAAemB,OAAOC,IAAtB,CAHR;;AAAA;AAGXC,sBAHW;AAAA,8CAIRA,UAJQ;;AAAA;AAAA;AAAA;AAAA,kBAMTxC,mBANS;;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,GAAnB;AASD,CA7ED;AA8EA;;;;;;;;;;;;;kBAaeC,W","file":"collectFeed.js","sourcesContent":["import fs from \"fs-extra\";\nimport path from \"path\";\nimport through2 from \"through2\";\nimport Feedparser from \"feedparser\";\nimport { _fetch } from \"./util\";\nimport config from \"../../config/config.json\";\nimport source from \"../../config/source.json\";\nconst rootPath = process.env.rootPath || path.join(__dirname, \"..\", \"..\");\nvar Promise = require(\"bluebird\");\n\n/**\n * This function scrap details text of each news feed while autoupdating\n * Scarping is done by a custom node modules by cherrioreq.\n * @param {string} itemUrl - Url of the news sources for specific news feed\n * @param {any} scrapeIdentity - The tag contains the details of the new we interested.\n * @returns promise\n */\nconst scrapDescription = (itemUrl, scrapeIdentity) => {\n  const cheerioReq = require(\"cheerio-req\");\n  return new Promise(resolve => {\n    cheerioReq(itemUrl, (err, $) => {\n      var totalNews = [];\n      if (err) console.log(err);\n      let $links = $(scrapeIdentity);\n      for (let i = 0; i < $links.length; ++i) {\n        totalNews.push($links.eq(i).text());\n      }\n      resolve(totalNews);\n    });\n  });\n};\n\nconst altDes = item => {\n  const htmlToText = require(\"html-to-text\");\n  return htmlToText.fromString(\n    item.description ||\n      item[\"content:encoded\"][1] ||\n      \"no description available\",\n    {\n      hideLinkHrefIfSameAsText: true,\n      ignoreHref: true,\n      ignoreImage: true\n    }\n  );\n};\n/**\n * This will exculde only the required information form stream source for each feed\n * and return a formated version of feed\n * @param {object} item\n * @returns object\n */\nconst formatItem = async function(item, scrapeIdentity) {\n  if (item && typeof item === \"object\") {\n    let descriptin;\n    if (config.local.newsSetting.scrapping) {\n      descriptin = await scrapDescription(item.link, scrapeIdentity); // this is the main description fetched from main site\n    } else descriptin = altDes(item); // this is the short descriptin comes from feed after normalize html signs\n\n    // finding an image from feed is bit of problem, so needed to go through some\n    // extra mechanism\n    let img = item[\"rss:image\"];\n    if (img) {\n      var tag = img[\"#\"] === undefined\n        ? img[\"url\"] ? img[\"url\"][\"#\"] : \"none\"\n        : img[\"#\"];\n    }\n    let result = await {\n      title: item.title,\n      description: descriptin,\n      pubDate: item.pubDate,\n      image: tag,\n      link: item.link\n    };\n    return result;\n  }\n  throw Error(\"item feeds cant be formatted\");\n};\n\nconst CollectFeed = function(sourceTitle, sourceUrl, lastFirstFeedTitle) {\n  this.sourceUrl = sourceUrl;\n  this.sourceTitle = sourceTitle;\n  this.scrapTag = source[sourceTitle].jsonFile;\n  this.feedCollection = [];\n  this.fetch = _fetch;\n  this.writeFile = (fileName, fileToWrite) => {\n    try {\n      if (typeof fileToWrite !== \"undefined\") {\n        fs.writeJson(\n          path.join(rootPath, \"store\", this.sourceTitle, fileName + \".json\"),\n          fileToWrite\n        );\n        console.log(\"Feed parsed from %s\", this.sourceTitle);\n      }\n    } catch (e) {\n      console.log(e);\n    }\n  };\n  this.processWrite = (fileName, dataToWrite) => {\n    let self = this;\n    let fileFolder = path.join(rootPath, \"store\", this.sourceTitle);\n    fs.ensureDir(fileFolder, e => {\n      self.writeFile(fileName, dataToWrite);\n    });\n  };\n  var self = this;\n  this.formatXml = Response => {\n    return new Promise((resolve, reject) => {\n      var feedCollection = {};\n      return Response.pipe(new Feedparser())\n        .pipe(\n          through2.obj(function(chunk, enc, callback) {\n            // here it will cross check with old feed first item with newly chunked from stream\n            // if old feed first item title is equal with new first source item then we will cancel\n            // fetching as there is nothing new to update\n            if (chunk.title === lastFirstFeedTitle) {\n              return resolve({ isUpdateAvailable: false });\n            }\n            // if new items available then process will be continued\n            new Promise((resolve, reject) => {\n              resolve(formatItem(chunk, self.scrapTag));\n            }).then(v => {\n              this.push(v);\n              callback();\n            });\n          })\n        )\n        .on(\"error\", e => {\n          throw Error(e);\n        })\n        .on(\"data\", data => {\n          feedCollection[data.title] = data;\n        })\n        .on(\"end\", () => {\n          var timeNow = Date.now(); // this time will use as a refrence into file name\n\n          this.processWrite(timeNow, feedCollection);\n          resolve({\n            feedsLength: Object.keys(feedCollection).length,\n            fileName: timeNow + \".json\",\n            feeds: feedCollection,\n            isUpdateAvailable: true\n          });\n        });\n    });\n  };\n\n  this.initCollect = async function() {\n    try {\n      let getXml = await self.fetch(sourceUrl);\n      let processXml = await self.formatXml(getXml.body);\n      return processXml;\n    } catch (error) {\n      throw Error(error);\n    }\n  };\n};\n/*\n    return new Promise((resolve, reject) => {\n      self.fetch(sourceUrl).then(response => {\n        if (response.status === 200) {\n          return resolve(response.body);\n        }\n        reject(response.status);\n      });\n    }).then(response => {\n      return Promise.resolve(self.formatXml(response));\n    });\n    */\n\nexport default CollectFeed;\n"]}